{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMyfkw8VBlIYJYD9FlzI2/M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fantiflex/MuOn-optimizer/blob/main/Main_for_global_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"gpu\")\n",
        "\n",
        "%run \"/content/drive/MyDrive/Colab_Notebooks/EECS182_project/hyperspherical_descent.ipynb\"\n",
        "%run \"/content/drive/MyDrive/Colab_Notebooks/EECS182_project/Optimizers_project_182.ipynb\"\n",
        "%run \"/content/drive/MyDrive/Colab_Notebooks/EECS182_project/LGFBS_global.ipynb\"\n",
        "# after this, the functions defined inside those notebooks are available in the current notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX_PDnXkgWkM",
        "outputId": "1d409d8d-d46d-47fa-9fa0-d20a3fad53fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "em6Mx4-5gGZM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c966b356-1387-44fc-a841-488e47c12ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [01:07<00:00, 2.53MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with: manifold_muon_general\n",
            "Epochs: 5 --- LR: 0.001 \n",
            "Epoch 1, Loss: 2.3724129783863925, Time: 11.9055 seconds\n",
            "Epoch 2, Loss: 2.3148862488415776, Time: 11.8511 seconds\n",
            "Epoch 3, Loss: 2.278703212738037, Time: 11.9783 seconds\n",
            "Epoch 4, Loss: 2.25679129970317, Time: 11.7540 seconds\n",
            "Epoch 5, Loss: 2.246371094061404, Time: 11.5793 seconds\n",
            "Accuracy of the network on the 10000 test images: 19.05 %\n",
            "Accuracy of the network on the 50000 train images: 18.408 %\n",
            "Saving results to results/update-manifold_muon_general-lr-0.001-wd-0.0-seed-42.pkl\n",
            "Results saved to results/update-manifold_muon_general-lr-0.001-wd-0.0-seed-42.pkl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124), (0.24703233, 0.24348505, 0.26158768))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=1024, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1024, shuffle=False)\n",
        "\n",
        "\n",
        "OPTS = {}\n",
        "\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 128, bias=False)\n",
        "        self.fc2 = nn.Linear(128, 64, bias=False)\n",
        "        self.fc3 = nn.Linear(64, 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 32 * 32 * 3)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(epochs, initial_lr, update, wd):\n",
        "    model = MLP().cuda()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if update == AdamW:\n",
        "        optimizer = AdamW(model.parameters(), lr=initial_lr, weight_decay=wd)\n",
        "    else:\n",
        "        assert update in [manifold_muon, hyperspherical_descent, manifold_muon_general]\n",
        "        optimizer = None\n",
        "        if update == manifold_muon_general:\n",
        "          opts = {p: ManifoldLBFGS(eta=initial_lr, history=10, eps_curv=1e-12) for p in model.parameters()}\n",
        "\n",
        "    steps = epochs * len(train_loader)\n",
        "    step = 0\n",
        "\n",
        "    if optimizer is None:\n",
        "      for p in model.parameters():\n",
        "          if update == manifold_muon_general:\n",
        "              p.data = update(p.data, torch.zeros_like(p.data), eta=0.0, opt=opts[p])\n",
        "          else:\n",
        "              p.data = update(p.data, torch.zeros_like(p.data), eta=0.0)\n",
        "\n",
        "\n",
        "    epoch_losses = []\n",
        "    epoch_times = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        running_loss = 0.0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward and optimize\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            lr = initial_lr * (1 - step / steps)\n",
        "            with torch.no_grad():\n",
        "                if optimizer is None:\n",
        "                    if update == manifold_muon_general:\n",
        "                      # 1) Finaliser la paire (s,y) précédente avec le gradient courant\n",
        "                      for p in model.parameters():\n",
        "                        if getattr(opts[p], \"last\", None) is not None:\n",
        "                          opts[p].update(p.grad)\n",
        "\n",
        "                      # 2) Nouveau pas L-BFGS (note le opt=..., et p.data)\n",
        "                      for p in model.parameters():\n",
        "                          p.data = update(p.data, p.grad, eta=lr, opt=opts[p])\n",
        "                else:\n",
        "                    # Cas stateless\n",
        "                    for p in model.parameters():\n",
        "                        p.data = update(p.data, p.grad, eta=lr)\n",
        "\n",
        "            step += 1\n",
        "            running_loss += loss.item()\n",
        "            if (i+1) % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_time = end_time - start_time\n",
        "        epoch_losses.append(epoch_loss)\n",
        "        epoch_times.append(epoch_time)\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss}, Time: {epoch_time:.4f} seconds\")\n",
        "    return model, epoch_losses, epoch_times\n",
        "\n",
        "\n",
        "def eval(model):\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        accs = []\n",
        "        for dataloader in [test_loader, train_loader]:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in dataloader:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "            accs.append(100 * correct / total)\n",
        "\n",
        "    print(f\"Accuracy of the network on the {len(test_loader.dataset)} test images: {accs[0]} %\")\n",
        "    print(f\"Accuracy of the network on the {len(train_loader.dataset)} train images: {accs[1]} %\")\n",
        "    return accs\n",
        "\n",
        "def weight_stats(model):\n",
        "    singular_values = []\n",
        "    norms = []\n",
        "    for p in model.parameters():\n",
        "        u,s,v = torch.svd(p)\n",
        "        singular_values.append(s)\n",
        "        norms.append(p.norm())\n",
        "    return singular_values, norms\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Train a model on CIFAR-10.\")\n",
        "    parser.add_argument(\"--epochs\", type=int, default=5, help=\"Number of epochs to train for.\")\n",
        "    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Initial learning rate.\")\n",
        "    parser.add_argument(\"--update\", type=str, default=\"manifold_muon_general\", choices=[\"manifold_muon\", \"hyperspherical_descent\", \"adam\",\"manifold_muon_general\"], help=\"Update rule to use.\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Seed for the random number generator.\")\n",
        "    parser.add_argument(\"--wd\", type=float, default=0.0, help=\"Weight decay for AdamW.\")\n",
        "    args = parser.parse_args([])\n",
        "\n",
        "    # determinism flags\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    update_rules = {\n",
        "        \"manifold_muon\": manifold_muon,\n",
        "        \"hyperspherical_descent\": hyperspherical_descent,\n",
        "        \"adam\": AdamW,\n",
        "        \"manifold_muon_general\": manifold_muon_general\n",
        "    }\n",
        "\n",
        "    update = update_rules[args.update]\n",
        "\n",
        "    print(f\"Training with: {args.update}\")\n",
        "    print(f\"Epochs: {args.epochs} --- LR: {args.lr}\", f\"--- WD: {args.wd}\" if args.update == \"adam\" else \"\")\n",
        "\n",
        "    model, epoch_losses, epoch_times = train(\n",
        "        epochs=args.epochs,\n",
        "        initial_lr=args.lr,\n",
        "        update=update,\n",
        "        wd=args.wd\n",
        "    )\n",
        "    test_acc, train_acc = eval(model)\n",
        "    singular_values, norms = weight_stats(model)\n",
        "\n",
        "    results = {\n",
        "        \"epochs\": args.epochs,\n",
        "        \"lr\": args.lr,\n",
        "        \"seed\": args.seed,\n",
        "        \"wd\": args.wd,\n",
        "        \"update\": args.update,\n",
        "        \"epoch_losses\": epoch_losses,\n",
        "        \"epoch_times\": epoch_times,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"train_acc\": train_acc,\n",
        "        \"singular_values\": singular_values,\n",
        "        \"norms\": norms\n",
        "    }\n",
        "\n",
        "    filename = f\"update-{args.update}-lr-{args.lr}-wd-{args.wd}-seed-{args.seed}.pkl\"\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "    print(f\"Saving results to {os.path.join(\"results\", filename)}\")\n",
        "    with open(os.path.join(\"results\", filename), \"wb\") as f:\n",
        "        pickle.dump(results, f)\n",
        "    print(f\"Results saved to {os.path.join(\"results\", filename)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efef7867"
      },
      "source": [
        "First, uninstall the current PyTorch version. This command will prompt you for confirmation, so make sure to type `y` and press Enter when asked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "997783d4",
        "outputId": "93c65324-6097-4af0-926a-f459aff66f7c"
      },
      "source": [
        "!pip uninstall torch torchvision torchaudio -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60eb6a2f"
      },
      "source": [
        "Next, install the desired PyTorch version. You can find the installation command for specific versions and CUDA compatibility on the official PyTorch website (`pytorch.org/get-started/locally/`).\n",
        "\n",
        "For example, to install the latest stable version with CUDA 11.8 (common in Colab), you might use something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "762b7306",
        "outputId": "1c9c073b-48f8-4228-a17b-4cf701b803f7"
      },
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m828.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (905.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.2/905.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp312-cp312-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118 triton-3.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "74c53ccc3bd444ee946d96403bc54164"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d58f48e2"
      },
      "source": [
        "After running these commands, you should restart the runtime (`Runtime > Restart runtime` from the menu) for the changes to take effect. Then, you can verify the installed version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5ebf5f9",
        "outputId": "f79787b6-c4e1-40b9-fc39-ef419b4bc0a5"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c573f376"
      },
      "source": [
        "Keep in mind that Colab environments are updated periodically, so a specific PyTorch version might become the default over time."
      ]
    }
  ]
}